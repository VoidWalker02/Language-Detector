# -*- coding: utf-8 -*-
"""Language Detector

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OWTa0cekScqNY0VAv_ZpKxMLvV6NxcCR
"""

!wget -P /content/jrc 'https://wt-public.emm4u.eu/Acquis/JRC-Acquis.3.0/corpus/jrc-en.tgz'
!wget -P /content/jrc 'https://wt-public.emm4u.eu/Acquis/JRC-Acquis.3.0/corpus/jrc-de.tgz'
!wget -P /content/jrc 'https://wt-public.emm4u.eu/Acquis/JRC-Acquis.3.0/corpus/jrc-es.tgz'
!wget -P /content/jrc 'https://wt-public.emm4u.eu/Acquis/JRC-Acquis.3.0/corpus/jrc-fr.tgz'

!mkdir /content/jrc/en
!mkdir /content/jrc/de
!mkdir /content/jrc/es
!mkdir /content/jrc/fr
!tar -xzvf /content/jrc/jrc-en.tgz -C /content/jrc/en
!tar -xzvf /content/jrc/jrc-de.tgz -C /content/jrc/de
!tar -xzvf /content/jrc/jrc-es.tgz -C /content/jrc/es
!tar -xzvf /content/jrc/jrc-fr.tgz -C /content/jrc/fr

import os
import pandas as pd

def load_texts_from_directory(directory, label):
    texts = []
    # Walk through all subdirectories and files
    for root, _, files in os.walk(directory):
        for filename in files:
            filepath = os.path.join(root, filename)
            # Read the file, assuming it's plain text
            with open(filepath, 'r', encoding='utf-8') as file:
                text = file.read()
                texts.append((text, label))
    return texts

# Load texts from each language directory
data = []
data.extend(load_texts_from_directory('/content/jrc/en', 'english'))
data.extend(load_texts_from_directory('/content/jrc/de', 'german'))
data.extend(load_texts_from_directory('/content/jrc/es', 'spanish'))
data.extend(load_texts_from_directory('/content/jrc/fr', 'french'))

# Convert to DataFrame
df = pd.DataFrame(data, columns=['text', 'label'])
print(df.head())
print(f"Loaded {len(df)} texts in total.")

import os
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report
import re

class LanguageDetector:
    def __init__(self, languages=['english', 'spanish', 'french', 'german']):
        self.languages = languages
        self.vectorizer = CountVectorizer(
            analyzer='char',
            ngram_range=(1, 3),
            min_df=5,
            max_features=1000
        )
        self.classifier = MultinomialNB()

    def preprocess_text(self, text):
        # Convert to lowercase and remove special characters
        text = text.lower()
        text = re.sub(r'[!@#$%^&*(),.?":{}|<>]', '', text)
        return text

    def prepare_data(self, texts, labels):
        # Preprocess all texts
        processed_texts = [self.preprocess_text(text) for text in texts]
        # Create feature vectors
        X = self.vectorizer.fit_transform(processed_texts)
        return X, labels

    def train(self, texts, labels):
        """
        Train the language detection model

        Parameters:
        texts: list of strings (training texts)
        labels: list of strings (language labels)
        """
        X, y = self.prepare_data(texts, labels)
        # Split into training and validation sets
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.1, random_state=42
        )

        # Train the model
        self.classifier.fit(X_train, y_train)

        # Evaluate on validation set
        val_predictions = self.classifier.predict(X_val)
        print("\nValidation Results:")
        print(classification_report(y_val, val_predictions))

    def predict(self, text):
        """
        Predict the language of a given text

        Parameters:
        text: string (text to analyze)

        Returns:
        predicted_language: string
        confidence: float
        """
        processed_text = self.preprocess_text(text)
        X = self.vectorizer.transform([processed_text])
        prediction = self.classifier.predict(X)[0]
        probabilities = self.classifier.predict_proba(X)[0]
        confidence = max(probabilities)

        return prediction, confidence

# Load and prepare data
data = []
data.extend(load_texts_from_directory('/content/jrc/en', 'english'))
data.extend(load_texts_from_directory('/content/jrc/de', 'german'))
data.extend(load_texts_from_directory('/content/jrc/es', 'spanish'))
data.extend(load_texts_from_directory('/content/jrc/fr', 'french'))

# Convert to DataFrame
df = pd.DataFrame(data, columns=['text', 'label'])
print(df.head())
print(f"Loaded {len(df)} texts in total.")

# Initialize and train the model
detector = LanguageDetector()
df_sample = df.sample(frac=0.3, random_state=42)
detector.train(df_sample['text'], df_sample['label'])

# Test the model with a new text
test_text = "This is a sample English text for testing."
lang, conf = detector.predict(test_text)
print(f"\nTest prediction:")
print(f"Text: {test_text}")
print(f"Predicted language: {lang}")
print(f"Confidence: {conf:.2f}")

test_text = "Das Kinder."
lang, conf = detector.predict(test_text)
print(f"\nTest prediction:")
print(f"Text: {test_text}")
print(f"Predicted language: {lang}")
print(f"Confidence: {conf:.2f}")